RocketMQ

1. 支持事务消息
2. 支持定时消息

可靠性：

复制：

1. 同步复制
2. 异步复制

刷盘：

1. 同步刷盘
2. 异步刷盘

支持四种部署模式：

1. 单Mater
2. 多Master模式
3. 多Master多Slave模式，异步复制
4. 多Master多Slave模式，同步双写

发送消息类型：

1. 同步
2. 异步
3. 单向

保证消息可靠性：

消息发送可靠性：

1. 同步发送
   同步发送是指发送端在发送消息时，阻塞线程进行等待，直到服务器返回发送的结果。发送端如果需要保证消息的可靠性，防止消息发送失败，可以采用同步阻塞式的发送，然后同步检查Brocker返回的状态来判断消息是否持久化成功。如果发送超时或者失败，则会默认重试2次，RocketMQ选择至少传输成功一次的消息模型，但是有可能发生重复投递，因为网络传输是不可靠的
2. 异步发送
   异步发送是指发送端在发送消息时，传入回调接口实现类，调用该发送接口后不会阻塞，发送方法会立即返回，回调任务会在另一个线程中执行，消息发送结果会回传给相应的回调函数。具体的业务实现可以根据发送的结果信息来判断是否需要重试来保证消息的可靠性。
3. 单向发送
   单向发送是指发送端发送完成之后，调用该发送接口后立刻返回，并不返回发送的结果，业务方无法根据发送的状态来判断消息是否发送成功，单向发送相对前两种发送方式来说是一种不可靠的消息发送方式，因此要保证消息发送的可靠性，不推荐采用这种方式来发送消息。

存储消息的可靠性：

- 单机的刷盘机制
- 主从之间的数据复制

如果设置为每条消息都强制刷盘、主从复制，那么性能无疑会降低；如果不这样设置，就会有一定的可能性丢失消息。RocketMQ一般都是先把消息写到PageCache中，然后再持久化到磁盘上，数据从pagecache刷新到磁盘有两种方式，同步和异步。

1. 同步刷盘
   消息写入内存的 PageCache后，立刻通知刷盘线程刷盘，然后等待刷盘完成，刷盘线程执行完成后唤醒等待的线程，返回消息写成功的状态。这种方式可以保证数据绝对安全，但是吞吐量不大。
2. 异步刷盘（默认）
   消息写入到内存的 PageCache中，就立刻给客户端返回写操作成功，当 PageCache中的消息积累到一定的量时，触发一次写操作，或者定时等策略将 PageCache中的消息写入到磁盘中。这种方式吞吐量大，性能高，但是 PageCache中的数据可能丢失，不能保证数据绝对的安全。

消费端消息可靠性：

1. 消费重试
   消费者从RocketMQ拉取到消息之后，需要返回消费成功来表示业务方正常消费完成。因此只有返回CONSUME_SUCCESS才算消费完成，如果返回CONSUME_LATER则会按照不同的messageDelayLevel时间进行再次消费，时间分级从秒到小时，最长时间为2个小时后再次进行消费重试，如果消费满16次之后还是未能消费成功，则不再重试，会将消息发送到死信队列，从而保证消息存储的可靠性。
2. 死信队列
   未能成功消费的消息，消息队列并不会立刻将消息丢弃，而是将消息发送到死信队列，其名称是在原队列名称前加%DLQ%，如果消息最终进入了死信队列，则可以通过RocketMQ提供的相关接口从死信队列获取到相应的消息，保证了消息消费的可靠性。
3. 消息回溯
   回溯消费是指Consumer已经消费成功的消息，或者之前消费业务逻辑有问题，现在需要重新消费。要支持此功能，则Broker存储端在向Consumer消费端投递成功消息后，消息仍然需要保留。重新消费一般是按照时间维度，例如由于Consumer系统故障，恢复后需要重新消费1小时前的数据。RocketMQ Broker提供了一种机制，可以按照时间维度来回退消费进度，这样就可以保证只要发送成功的消息，只要消息没有过期，消息始终是可以消费到的。

文件清理：

RocketMQ中被消费的消息是不会删除的，所以保证了文件的顺序写入。如果不清理文件的话，文件数量不断地增加，最终会导致磁盘可用空间越来越少。

默认72小时文件过期

删除方式：

1. 通过定时任务，每天凌晨4点，删除过期文件
2. 磁盘使用空间超过75%，开始删除文件
   如果磁盘空间超过85%，会开始批量清理文件，不管有没有过期，直到空间充足
   如果磁盘空间使用率超过90%，会拒绝写入

消息重试：

默认重试16次，还失败之后会送入死信队列，私信队列的消息需要人工处理。













Kafka

1. 支持事务消息（2PC）
2. 不支持定时消息

消息类型：

1. 简单消息
2. 同步消息
3. 异步发送消息

三种部署模式：

1. 单broker模式

2. 单机多broker模式

3. 多机多broker模式
   Topic可以分区 ---> Partition（可以有副本）
   Partition ---> Segment(一个数据文件、两个索引文件)

   <img src="C:\Users\ranji\AppData\Roaming\Typora\typora-user-images\image-20210602153227231.png" alt="image-20210602153227231" style="zoom:50%;" align='left'/>

架构

<img src="C:\Users\ranji\AppData\Roaming\Typora\typora-user-images\image-20210602153828755.png" alt="image-20210602153828755" style="zoom:50%;" align='left'/>

可靠性消息投递：



ACK应答机制：

1. acks=0
   producer不等待broker的ack
2. acks=1(默认)
   producer等待broker的ack，partition的leader落盘成功后返回ack
3. acks=-1(all)
   producer等待broker的ack，partition的leader和follower全部落盘才会ack

broker存储原理：

消息保留（清理机制）：

1. 直接删除（默认）
   日志删除是通过定时任务来实现的，默认5分钟执行一次，看看有没有需要删除的数据
   按照时间删除：默认超过168小时的日志会被删除，也可以自己配置时间
   按照大小删除：可以配置所有文件的大小（默认无限制）或者配置segment文件大小（默认1G）
2. 压缩策略
   合并相同的key

高可用架构：

1. Broker的controller选举
   所有的Broker会尝试在zookeeper中创建临时节点/controller，只有一个能创建成功（先到先得）
   如果controller挂掉了或者网络出现了问题，ZK上的临时节点会消失。其他的Broker通过watch监听到Controller下线的消息后，开始竞选新的Controller
2. 分区副本Leader选举
   默认让ISR中的第一个replica变成leader

主从同步



吞吐量：

支持的消息类型：定时消息、顺序消息、事务消息

数据安全和稳定性：

Kafka快的原因：

1. 顺序读写

2. 它把所有消息都变成一个批量的文件，并且进行合理的批量压缩，减少网络IO损耗

3. 零拷贝非零拷贝  
   磁盘->内核缓冲区->用户缓冲区->socket缓冲区->网卡设备

   一共发生了四次用户态和内核态的切换和4次数据拷贝，2次系统函数的调用(read,write)

   Linux操作系统里面提供一个sendfile函数，可以实现零拷贝。这个时候不需要经过用户缓冲区，直接把数据拷贝到网卡。

   因为这个只有DMA拷贝，没有CPU拷贝，所以叫做”零拷贝“，零拷贝至少可以提高一倍的性能。

   Kafka文件传输最终调用的是Java NIO库里的transferTo方法

4. 分区概念，一个Topic可以设置多个分区文件，实现负载。

   每个partition还会切分为segment，防止文件多大（默认最大1G），读取数据慢

5. kafka性吞吐量更高主要是由于Producer端将多个小消息合并，批量发向Broker。kafka采用异步发送的机制，当发送一条消息时，消息并没有发送到broker而是缓存起来，然后直接向业务返回成功，当缓存的消息达到一定数量时再批量发送。

   此时减少了网络io，从而提高了消息发送的性能，但是如果消息发送者宕机，会导致消息丢失，业务出错，所以理论上kafka利用此机制提高了io性能却降低了可靠性。
